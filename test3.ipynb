{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import ray\n",
    "from ray import tune, train\n",
    "from ray.tune import CLIReporter, ExperimentAnalysis\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air import session\n",
    "from ray.train import Checkpoint\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.verbose = True\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r'D:\\School\\ADMU\\4Y\\SEM 1\\MATH 199.11\\Final\\DAILY\\LUZ_Daily_Complete.csv'\n",
    "data = pd.read_csv(input_file)\n",
    "data = data.fillna(0)\n",
    "\n",
    "\n",
    "X = data.values\n",
    "\n",
    "y = data[['GWAP','LWAP']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(X))  # 60% for training\n",
    "val_size = int(0.20 * len(X))   # 20% for validation\n",
    "test_size = len(X) - train_size - val_size  # Remaining 15% for testing\n",
    "\n",
    "train_data = X[:train_size]\n",
    "train_labels = y[:train_size]\n",
    "\n",
    "val_data = X[train_size:train_size + val_size]\n",
    "val_labels = y[train_size:train_size + val_size]\n",
    "\n",
    "test_data = X[train_size + val_size:]\n",
    "test_labels = y[train_size + val_size:]\n",
    "seq_len=7\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_features(data):\n",
    "    minmax_cols = []\n",
    "    boxcox_cols = []\n",
    "    yeojohnson_cols = []\n",
    "\n",
    "    for i in range(data.shape[1]):  # Iterate over columns by index\n",
    "        col_data = data[:, i]  # Get each column as a separate array\n",
    "        skewness = skew(col_data)\n",
    "        kurt = kurtosis(col_data)\n",
    "        is_positive = np.all(col_data > 0)\n",
    "\n",
    "        if -1 <= skewness <= 1 and -1 <= kurt <= 1:\n",
    "            minmax_cols.append(i)  # Add index for MinMax family\n",
    "        elif is_positive:\n",
    "            boxcox_cols.append(i)  # Add index for BoxCox family\n",
    "        else:\n",
    "            yeojohnson_cols.append(i)  # Add index for YeoJohnson family\n",
    "\n",
    "    return minmax_cols, boxcox_cols, yeojohnson_cols\n",
    "\n",
    "minmax_cols, boxcox_cols, yeojohnson_cols = classify_features(X)\n",
    "\n",
    "transformers = [\n",
    "    ('minmax', MinMaxScaler(), minmax_cols),\n",
    "    ('boxcox_minmax', Pipeline([\n",
    "        ('boxcox', PowerTransformer(method='box-cox', standardize=False)),\n",
    "        ('minmax', MinMaxScaler())\n",
    "    ]), boxcox_cols),\n",
    "    ('yeojohnson_minmax', Pipeline([\n",
    "        ('yeojohnson', PowerTransformer(method='yeo-johnson', standardize=False)),\n",
    "        ('minmax', MinMaxScaler())\n",
    "    ]), yeojohnson_cols)\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "# Build the full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.fit(train_data)\n",
    "transformed_train_data = pipeline.transform(train_data)\n",
    "transformed_val_data = pipeline.transform(val_data)\n",
    "transformed_test_data = pipeline.transform(test_data)\n",
    "\n",
    "minmax_colsy, boxcox_colsy, yeojohnson_colsy = classify_features(y)\n",
    "transformersy = [\n",
    "    ('minmax', MinMaxScaler(), minmax_colsy),\n",
    "    ('boxcox_minmax', Pipeline([\n",
    "        ('boxcox', PowerTransformer(method='box-cox', standardize=False)),\n",
    "        ('minmax', MinMaxScaler())\n",
    "    ]), boxcox_colsy),\n",
    "    ('yeojohnson_minmax', Pipeline([\n",
    "        ('yeojohnson', PowerTransformer(method='yeo-johnson', standardize=False)),\n",
    "        ('minmax', MinMaxScaler())\n",
    "    ]), yeojohnson_colsy)\n",
    "]\n",
    "preprocessory = ColumnTransformer(transformers=transformersy)\n",
    "\n",
    "# Build the full pipeline\n",
    "pipeliney = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessory)\n",
    "])\n",
    "pipeliney.fit(train_labels)\n",
    "\n",
    "transformed_train_labels = pipeliney.transform(train_labels)\n",
    "transformed_val_labels = pipeliney.transform(val_labels)\n",
    "transformed_test_labels = pipeliney.transform(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx:idx+self.seq_len], self.y[idx+self.seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(transformed_train_data, transformed_train_labels, seq_len)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = TimeSeriesDataset(transformed_val_data, transformed_val_labels, seq_len)    \n",
    "val_dataloader = DataLoader(val_dataset, batch_size, shuffle=False) \n",
    "\n",
    "test_dataset = TimeSeriesDataset(transformed_test_data, transformed_test_labels, seq_len)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCustomCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, activation_fn):\n",
    "        super(LSTMCustomCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "        # Combine all gate matrices into one large matrix for efficiency\n",
    "        self.W_ih = nn.Linear(input_size, 4 * hidden_size, bias=False)\n",
    "        self.W_hh = nn.Linear(hidden_size, 4 * hidden_size, bias=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(4 * hidden_size))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        h, c = hidden\n",
    "        \n",
    "        # Optimized matrix multiplication and bias addition\n",
    "        gates = self.W_ih(x) + self.W_hh(h) + self.bias\n",
    "        \n",
    "        # Split into 4 gate vectors\n",
    "        i_gate, f_gate, o_gate, g_gate = torch.chunk(gates, 4, dim=1)\n",
    "        \n",
    "        # Sigmoid activations for gates\n",
    "        i_gate = torch.sigmoid(i_gate)\n",
    "        f_gate = torch.sigmoid(f_gate)\n",
    "        o_gate = torch.sigmoid(o_gate)\n",
    "        \n",
    "        # Apply the custom activation function for the cell gate\n",
    "        g_gate = self.activation_fn(g_gate)\n",
    "        \n",
    "        # Compute the new cell state\n",
    "        c_next = f_gate * c + i_gate * g_gate\n",
    "        \n",
    "        # Compute the new hidden state using the custom activation function\n",
    "        h_next = o_gate * self.activation_fn(c_next)\n",
    "        \n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCustom(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, activation_fn=torch.tanh, batch_first=False):\n",
    "        super(LSTMCustom, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation_fn = activation_fn\n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "        # Create a list of LSTM cells\n",
    "        self.cells = nn.ModuleList([LSTMCustomCell(input_size if i == 0 else hidden_size, hidden_size, activation_fn) for i in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # Determine the correct input shape\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_len, _ = x.size()\n",
    "            x = x.transpose(0, 1)  # Convert to (seq_len, batch_size, input_size) for processing\n",
    "        else:\n",
    "            seq_len, batch_size, _ = x.size()\n",
    "        \n",
    "        if hidden is None:\n",
    "            # Initialize hidden and cell states with zeros\n",
    "            h = [torch.zeros(batch_size, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
    "            c = [torch.zeros(batch_size, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
    "        else:\n",
    "            h, c = hidden\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        # Iterate over each time step\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t, :, :]  # Input at time step t\n",
    "            for i, cell in enumerate(self.cells):\n",
    "\n",
    "                h[i], c[i] = cell(x_t, (h[i], c[i]))\n",
    "                x_t = h[i]  # Pass hidden state to the next layer\n",
    "\n",
    "            outputs.append(h[-1].unsqueeze(0))  # Collect output from the last layer\n",
    "        \n",
    "        # Stack the outputs across time steps\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        \n",
    "        # Convert output back to (batch_size, seq_len, hidden_size) if batch_first is True\n",
    "        if self.batch_first:\n",
    "            outputs = outputs.transpose(0, 1)\n",
    "        \n",
    "        # Return outputs and the last hidden and cell states\n",
    "        return outputs, (torch.stack(h), torch.stack(c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers,activation_fn):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = LSTMCustom(input_size, hidden_size, num_layers, activation_fn, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_size = train_data.shape[1]  # Number of features\n",
    "hidden_size = 128\n",
    "output_size = train_labels.shape[1]  # Number of output features\n",
    "num_layers = 2\n",
    "activation_fn = torch.relu\n",
    "model = LSTMModel(input_size, hidden_size,output_size, num_layers,activation_fn).to(device)\n",
    "epoch=100\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Use MSE loss for regression tasks\n",
    "optimizer = optim.AdamW(list(model.parameters()), lr=1e-4, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "def train(model, dataloader, device, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0  # Initialize total loss to 0\n",
    "\n",
    "    \n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Check for NaN values in inputs\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).to(device)\n",
    "        \n",
    "        # Check for NaN values in outputs\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Return the average loss over all batches\n",
    "    return total_loss / len(train_dataloader.dataset)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0  # Initialize total loss\n",
    "    \n",
    "\n",
    "    for i, (inputs, target) in enumerate(dataloader):  # Use `test_dataloader`\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        predictions = outputs.to(device)  \n",
    "    \n",
    "        loss = criterion(predictions, target)\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Return the average loss over all batches\n",
    "    \n",
    "    return total_loss/len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(config,epoch):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = LSTMModel(input_size, config[\"hidden_size\"], output_size, config[\"num_layers\"],activation_fn).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(list(model.parameters()), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    \n",
    "    \n",
    "\n",
    "    train_dataloader, val_dataloader = load_data()\n",
    "    for e in range(epoch):  # Replace with your actual number of epochs\n",
    "        train_loss = train(model, train_dataloader, device, optimizer, criterion)\n",
    "        val_loss = evaluate(model, val_dataloader, device, criterion)\n",
    "        \n",
    "\n",
    "        # Report the results\n",
    "        session.report(  # Highlighted change\n",
    "            {\"loss\": val_loss} # Highlighted change\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"hidden_size\": tune.choice([50, 100, 200]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-3)\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    metric_columns=[\"loss\", \"training_iteration\"]\n",
    ")\n",
    "\n",
    "def trial_dirname_creator(trial):\n",
    "    return f\"trial_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 23:08:13,306\tINFO worker.py:1807 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baf8fb9f80d4a5da38986ee33b8fd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.9.20</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.0.0.dev0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.20', ray_version='3.0.0.dev0', ray_commit='e1c4e58016f79c9c1134da45cea23e3345f5354b')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()  # Shutdown any existing Ray instances\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 23:08:18,018\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:18 (running for 00:00:00.18)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "+------------------------+----------+-------+---------------+-------------+--------------+----------------+\n",
      "| Trial name             | status   | loc   |   hidden_size |          lr |   num_layers |   weight_decay |\n",
      "|------------------------+----------+-------+---------------+-------------+--------------+----------------|\n",
      "| train_lstm_ccd7c_00000 | PENDING  |       |            50 | 0.00303588  |            3 |    1.77167e-06 |\n",
      "| train_lstm_ccd7c_00001 | PENDING  |       |           200 | 0.00993261  |            3 |    1.81793e-05 |\n",
      "| train_lstm_ccd7c_00002 | PENDING  |       |           100 | 0.000516985 |            3 |    7.9532e-06  |\n",
      "| train_lstm_ccd7c_00003 | PENDING  |       |           100 | 0.0159641   |            3 |    0.000664765 |\n",
      "| train_lstm_ccd7c_00004 | PENDING  |       |           100 | 0.00024212  |            2 |    2.66155e-06 |\n",
      "| train_lstm_ccd7c_00005 | PENDING  |       |           100 | 0.00101357  |            2 |    0.000151119 |\n",
      "| train_lstm_ccd7c_00006 | PENDING  |       |           100 | 0.00683436  |            2 |    0.000204409 |\n",
      "| train_lstm_ccd7c_00007 | PENDING  |       |           100 | 0.000319028 |            2 |    1.29385e-05 |\n",
      "| train_lstm_ccd7c_00008 | PENDING  |       |           100 | 0.0761971   |            3 |    2.1013e-05  |\n",
      "| train_lstm_ccd7c_00009 | PENDING  |       |           100 | 0.056448    |            2 |    1.01343e-05 |\n",
      "+------------------------+----------+-------+---------------+-------------+--------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:23 (running for 00:00:05.24)\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 8.000: -8951.834801883739 | Iter 4.000: -94103.97252508135 | Iter 2.000: -3049347.807473447 | Iter 1.000: -12495233.876768898\n",
      "Logical resource usage: 0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (9 PENDING, 1 TERMINATED)\n",
      "+------------------------+------------+----------------+---------------+-------------+--------------+----------------+---------+----------------------+\n",
      "| Trial name             | status     | loc            |   hidden_size |          lr |   num_layers |   weight_decay |    loss |   training_iteration |\n",
      "|------------------------+------------+----------------+---------------+-------------+--------------+----------------+---------+----------------------|\n",
      "| train_lstm_ccd7c_00001 | PENDING    |                |           200 | 0.00993261  |            3 |    1.81793e-05 |         |                      |\n",
      "| train_lstm_ccd7c_00002 | PENDING    |                |           100 | 0.000516985 |            3 |    7.9532e-06  |         |                      |\n",
      "| train_lstm_ccd7c_00003 | PENDING    |                |           100 | 0.0159641   |            3 |    0.000664765 |         |                      |\n",
      "| train_lstm_ccd7c_00004 | PENDING    |                |           100 | 0.00024212  |            2 |    2.66155e-06 |         |                      |\n",
      "| train_lstm_ccd7c_00005 | PENDING    |                |           100 | 0.00101357  |            2 |    0.000151119 |         |                      |\n",
      "| train_lstm_ccd7c_00006 | PENDING    |                |           100 | 0.00683436  |            2 |    0.000204409 |         |                      |\n",
      "| train_lstm_ccd7c_00007 | PENDING    |                |           100 | 0.000319028 |            2 |    1.29385e-05 |         |                      |\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                |           100 | 0.0761971   |            3 |    2.1013e-05  |         |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                |           100 | 0.056448    |            2 |    1.01343e-05 |         |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808 |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5 |                   10 |\n",
      "+------------------------+------------+----------------+---------------+-------------+--------------+----------------+---------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:28 (running for 00:00:10.34)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 8.000: -8951.834801883739 | Iter 4.000: -94103.97252508135 | Iter 2.000: -3049347.807473447 | Iter 1.000: -743808089.8774054\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (8 PENDING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc            |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00002 | PENDING    |                |           100 | 0.000516985 |            3 |    7.9532e-06  |                 |                      |\n",
      "| train_lstm_ccd7c_00003 | PENDING    |                |           100 | 0.0159641   |            3 |    0.000664765 |                 |                      |\n",
      "| train_lstm_ccd7c_00004 | PENDING    |                |           100 | 0.00024212  |            2 |    2.66155e-06 |                 |                      |\n",
      "| train_lstm_ccd7c_00005 | PENDING    |                |           100 | 0.00101357  |            2 |    0.000151119 |                 |                      |\n",
      "| train_lstm_ccd7c_00006 | PENDING    |                |           100 | 0.00683436  |            2 |    0.000204409 |                 |                      |\n",
      "| train_lstm_ccd7c_00007 | PENDING    |                |           100 | 0.000319028 |            2 |    1.29385e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                |           100 | 0.0761971   |            3 |    2.1013e-05  |                 |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808 |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416 |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "+------------------------+------------+----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:33 (running for 00:00:15.45)\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 8.000: -8951.834801883739 | Iter 4.000: -94103.97252508135 | Iter 2.000: -3395435.421890021 | Iter 1.000: -12495233.876768898\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (7 PENDING, 3 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00003 | PENDING    |                 |           100 | 0.0159641   |            3 |    0.000664765 |                 |                      |\n",
      "| train_lstm_ccd7c_00004 | PENDING    |                 |           100 | 0.00024212  |            2 |    2.66155e-06 |                 |                      |\n",
      "| train_lstm_ccd7c_00005 | PENDING    |                 |           100 | 0.00101357  |            2 |    0.000151119 |                 |                      |\n",
      "| train_lstm_ccd7c_00006 | PENDING    |                 |           100 | 0.00683436  |            2 |    0.000204409 |                 |                      |\n",
      "| train_lstm_ccd7c_00007 | PENDING    |                 |           100 | 0.000319028 |            2 |    1.29385e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                 |           100 | 0.0761971   |            3 |    2.1013e-05  |                 |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                 |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:38 (running for 00:00:20.51)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 8.000: -8951.834801883739 | Iter 4.000: -94103.97252508135 | Iter 2.000: -3395435.421890021 | Iter 1.000: -15179620.013360132\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00004 | RUNNING    | 127.0.0.1:32576 |           100 | 0.00024212  |            2 |    2.66155e-06 |                 |                      |\n",
      "| train_lstm_ccd7c_00005 | PENDING    |                 |           100 | 0.00101357  |            2 |    0.000151119 |                 |                      |\n",
      "| train_lstm_ccd7c_00006 | PENDING    |                 |           100 | 0.00683436  |            2 |    0.000204409 |                 |                      |\n",
      "| train_lstm_ccd7c_00007 | PENDING    |                 |           100 | 0.000319028 |            2 |    1.29385e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                 |           100 | 0.0761971   |            3 |    2.1013e-05  |                 |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                 |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "| train_lstm_ccd7c_00003 | TERMINATED | 127.0.0.1:38140 |           100 | 0.0159641   |            3 |    0.000664765 |     1.7864e+07  |                    1 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:43 (running for 00:00:25.55)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 8.000: -8951.834801883739 | Iter 4.000: -1281011.396245237 | Iter 2.000: -3395435.421890021 | Iter 1.000: -6887259.580624579\n",
      "Logical resource usage: 0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (4 PENDING, 6 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00006 | PENDING    |                 |           100 | 0.00683436  |            2 |    0.000204409 |                 |                      |\n",
      "| train_lstm_ccd7c_00007 | PENDING    |                 |           100 | 0.000319028 |            2 |    1.29385e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                 |           100 | 0.0761971   |            3 |    2.1013e-05  |                 |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                 |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "| train_lstm_ccd7c_00003 | TERMINATED | 127.0.0.1:38140 |           100 | 0.0159641   |            3 |    0.000664765 |     1.7864e+07  |                    1 |\n",
      "| train_lstm_ccd7c_00004 | TERMINATED | 127.0.0.1:32576 |           100 | 0.00024212  |            2 |    2.66155e-06 |     2.46792e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00005 | TERMINATED | 127.0.0.1:33464 |           100 | 0.00101357  |            2 |    0.000151119 |     8.94311e+08 |                    2 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:48 (running for 00:00:30.56)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 8.000: -16182.412630911005 | Iter 4.000: -336456.47127448604 | Iter 2.000: -3049347.807473447 | Iter 1.000: -1279285.284480261\n",
      "Logical resource usage: 0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (3 PENDING, 7 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00007 | PENDING    |                 |           100 | 0.000319028 |            2 |    1.29385e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                 |           100 | 0.0761971   |            3 |    2.1013e-05  |                 |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                 |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "| train_lstm_ccd7c_00003 | TERMINATED | 127.0.0.1:38140 |           100 | 0.0159641   |            3 |    0.000664765 |     1.7864e+07  |                    1 |\n",
      "| train_lstm_ccd7c_00004 | TERMINATED | 127.0.0.1:32576 |           100 | 0.00024212  |            2 |    2.66155e-06 |     2.46792e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00005 | TERMINATED | 127.0.0.1:33464 |           100 | 0.00101357  |            2 |    0.000151119 |     8.94311e+08 |                    2 |\n",
      "| train_lstm_ccd7c_00006 | TERMINATED | 127.0.0.1:15648 |           100 | 0.00683436  |            2 |    0.000204409 | 23413           |                    8 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:53 (running for 00:00:35.61)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 8.000: -16182.412630911005 | Iter 4.000: -1402187.6456199393 | Iter 2.000: -1866305.182472867 | Iter 1.000: -727847.3130054352\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (2 PENDING, 8 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00008 | PENDING    |                 |           100 | 0.0761971   |            3 |    2.1013e-05  |                 |                      |\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                 |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "| train_lstm_ccd7c_00003 | TERMINATED | 127.0.0.1:38140 |           100 | 0.0159641   |            3 |    0.000664765 |     1.7864e+07  |                    1 |\n",
      "| train_lstm_ccd7c_00004 | TERMINATED | 127.0.0.1:32576 |           100 | 0.00024212  |            2 |    2.66155e-06 |     2.46792e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00005 | TERMINATED | 127.0.0.1:33464 |           100 | 0.00101357  |            2 |    0.000151119 |     8.94311e+08 |                    2 |\n",
      "| train_lstm_ccd7c_00006 | TERMINATED | 127.0.0.1:15648 |           100 | 0.00683436  |            2 |    0.000204409 | 23413           |                    8 |\n",
      "| train_lstm_ccd7c_00007 | TERMINATED | 127.0.0.1:32200 |           100 | 0.000319028 |            2 |    1.29385e-05 |     5.76915e+06 |                    4 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-10-24 23:08:58 (running for 00:00:40.71)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 8.000: -16182.412630911005 | Iter 4.000: -1402187.6456199393 | Iter 2.000: -1866305.182472867 | Iter 1.000: -1279285.284480261\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (1 PENDING, 9 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00009 | PENDING    |                 |           100 | 0.056448    |            2 |    1.01343e-05 |                 |                      |\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "| train_lstm_ccd7c_00003 | TERMINATED | 127.0.0.1:38140 |           100 | 0.0159641   |            3 |    0.000664765 |     1.7864e+07  |                    1 |\n",
      "| train_lstm_ccd7c_00004 | TERMINATED | 127.0.0.1:32576 |           100 | 0.00024212  |            2 |    2.66155e-06 |     2.46792e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00005 | TERMINATED | 127.0.0.1:33464 |           100 | 0.00101357  |            2 |    0.000151119 |     8.94311e+08 |                    2 |\n",
      "| train_lstm_ccd7c_00006 | TERMINATED | 127.0.0.1:15648 |           100 | 0.00683436  |            2 |    0.000204409 | 23413           |                    8 |\n",
      "| train_lstm_ccd7c_00007 | TERMINATED | 127.0.0.1:32200 |           100 | 0.000319028 |            2 |    1.29385e-05 |     5.76915e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00008 | TERMINATED | 127.0.0.1:23984 |           100 | 0.0761971   |            3 |    2.1013e-05  |     1.06326e+13 |                    1 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 23:09:00,606\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Paulo John Mercado/ray_results/train_lstm_2024-10-24_23-08-18' in 0.0115s.\n",
      "2024-10-24 23:09:00,610\tINFO tune.py:1041 -- Total run time: 42.59 seconds (42.41 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-10-24 23:09:00 (running for 00:00:42.42)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 8.000: -16182.412630911005 | Iter 4.000: -1402187.6456199393 | Iter 2.000: -1866305.182472867 | Iter 1.000: -6887259.580624579\n",
      "Logical resource usage: 4.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/PAULOJ~1/AppData/Local/Temp/ray/session_2024-10-24_23-08-10_347821_32244/artifacts/2024-10-24_23-08-18/train_lstm_2024-10-24_23-08-18/driver_artifacts\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "| Trial name             | status     | loc             |   hidden_size |          lr |   num_layers |   weight_decay |            loss |   training_iteration |\n",
      "|------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------|\n",
      "| train_lstm_ccd7c_00000 | TERMINATED | 127.0.0.1:6808  |            50 | 0.00303588  |            3 |    1.77167e-06 | 36613.5         |                   10 |\n",
      "| train_lstm_ccd7c_00001 | TERMINATED | 127.0.0.1:2416  |           200 | 0.00993261  |            3 |    1.81793e-05 |     1.47512e+09 |                    1 |\n",
      "| train_lstm_ccd7c_00002 | TERMINATED | 127.0.0.1:42668 |           100 | 0.000516985 |            3 |    7.9532e-06  |     3.74152e+06 |                    2 |\n",
      "| train_lstm_ccd7c_00003 | TERMINATED | 127.0.0.1:38140 |           100 | 0.0159641   |            3 |    0.000664765 |     1.7864e+07  |                    1 |\n",
      "| train_lstm_ccd7c_00004 | TERMINATED | 127.0.0.1:32576 |           100 | 0.00024212  |            2 |    2.66155e-06 |     2.46792e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00005 | TERMINATED | 127.0.0.1:33464 |           100 | 0.00101357  |            2 |    0.000151119 |     8.94311e+08 |                    2 |\n",
      "| train_lstm_ccd7c_00006 | TERMINATED | 127.0.0.1:15648 |           100 | 0.00683436  |            2 |    0.000204409 | 23413           |                    8 |\n",
      "| train_lstm_ccd7c_00007 | TERMINATED | 127.0.0.1:32200 |           100 | 0.000319028 |            2 |    1.29385e-05 |     5.76915e+06 |                    4 |\n",
      "| train_lstm_ccd7c_00008 | TERMINATED | 127.0.0.1:23984 |           100 | 0.0761971   |            3 |    2.1013e-05  |     1.06326e+13 |                    1 |\n",
      "| train_lstm_ccd7c_00009 | TERMINATED | 127.0.0.1:24344 |           100 | 0.056448    |            2 |    1.01343e-05 |     8.88651e+11 |                    1 |\n",
      "+------------------------+------------+-----------------+---------------+-------------+--------------+----------------+-----------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x256a8f9bf10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.run(\n",
    "    tune.with_parameters(train_lstm, epoch=epoch),\n",
    "    resources_per_trial={\"cpu\": 4, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    verbose=1,\n",
    "    trial_dirname_creator=trial_dirname_creator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "def run(model, train_dataloader, val_dataloader, test_dataloader, device, epoch,optimizer):\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        \n",
    "        train_loss = train(model, train_dataloader, device, optimizer, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss=evaluate(model,val_dataloader,device,criterion)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "        \n",
    "\n",
    "        if train_loss < 1e-3 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.35611060704266667, Val Loss: 27023.070567499282\n",
      "Epoch 2, Training Loss: 0.3416177843397012, Val Loss: 64290.04404919991\n",
      "Epoch 3, Training Loss: 0.3281291240605843, Val Loss: 80591.20858007236\n",
      "Epoch 4, Training Loss: 0.3144710478815844, Val Loss: 104117.85447075989\n",
      "Epoch 5, Training Loss: 0.2989988830415943, Val Loss: 126766.85843084635\n",
      "Epoch 6, Training Loss: 0.2797932606492961, Val Loss: 259990.4709908647\n",
      "Epoch 7, Training Loss: 0.2545474135336356, Val Loss: 418465.8773688292\n",
      "Epoch 8, Training Loss: 0.21997605533859846, Val Loss: 698388.240536252\n",
      "Epoch 9, Training Loss: 0.17131063224544657, Val Loss: 1815302.9679194884\n",
      "Epoch 10, Training Loss: 0.10405718860175382, Val Loss: 8409335.734778084\n",
      "Epoch 11, Training Loss: 0.040319181425527185, Val Loss: 27214004.52807455\n",
      "Epoch 12, Training Loss: 0.06745215908574533, Val Loss: 28788104.31639882\n",
      "Epoch 13, Training Loss: 0.046496175514780455, Val Loss: 14506093.599998802\n",
      "Epoch 14, Training Loss: 0.041796312029981283, Val Loss: 18228678.92266541\n",
      "Epoch 15, Training Loss: 0.03917325536986238, Val Loss: 18733407.786532722\n",
      "Epoch 16, Training Loss: 0.03629023218721912, Val Loss: 25405952.01876329\n",
      "Epoch 17, Training Loss: 0.03581389264482356, Val Loss: 26563458.782555763\n",
      "Epoch 18, Training Loss: 0.03561627908054471, Val Loss: 29514376.306879662\n",
      "Epoch 19, Training Loss: 0.03439010557850386, Val Loss: 43516592.82369286\n",
      "Epoch 20, Training Loss: 0.03299145242782729, Val Loss: 37837194.14692103\n",
      "Epoch 21, Training Loss: 0.03173048199173884, Val Loss: 55809252.39152545\n",
      "Epoch 22, Training Loss: 0.03067480576961472, Val Loss: 56911238.46356411\n",
      "Epoch 23, Training Loss: 0.0297626430112566, Val Loss: 61699757.13969747\n",
      "Epoch 24, Training Loss: 0.028821383726085146, Val Loss: 60217244.56384299\n",
      "Epoch 25, Training Loss: 0.027804457684092898, Val Loss: 63200005.54195593\n",
      "Epoch 26, Training Loss: 0.026752853606181466, Val Loss: 79843652.16047266\n",
      "Epoch 27, Training Loss: 0.025792619295573842, Val Loss: 90355697.28256616\n",
      "Epoch 28, Training Loss: 0.0249103949104896, Val Loss: 96011367.15277177\n",
      "Epoch 29, Training Loss: 0.024032284961602805, Val Loss: 153179040.2459656\n",
      "Epoch 30, Training Loss: 0.023184910451176547, Val Loss: 160234459.1808907\n",
      "Epoch 31, Training Loss: 0.022394240520496933, Val Loss: 79134233.7992572\n",
      "Epoch 32, Training Loss: 0.021672174101155208, Val Loss: 91113545.68380839\n",
      "Epoch 33, Training Loss: 0.021003607759930695, Val Loss: 90655788.21586604\n",
      "Epoch 34, Training Loss: 0.020385257528096508, Val Loss: 113471149.13644923\n",
      "Epoch 35, Training Loss: 0.01982955017241621, Val Loss: 126553448.99231783\n",
      "Epoch 36, Training Loss: 0.01933813627524055, Val Loss: 164370623.55326557\n",
      "Epoch 37, Training Loss: 0.018895144758015663, Val Loss: 98599390.86246127\n",
      "Epoch 38, Training Loss: 0.018505441340382303, Val Loss: 97336135.84076051\n",
      "Epoch 39, Training Loss: 0.018162062231736505, Val Loss: 175086776.1859935\n",
      "Epoch 40, Training Loss: 0.01786566135665864, Val Loss: 204602964.7326801\n",
      "Epoch 41, Training Loss: 0.017602197918824836, Val Loss: 247108114.4304556\n",
      "Epoch 42, Training Loss: 0.017366971688781565, Val Loss: 254844132.3872301\n",
      "Epoch 43, Training Loss: 0.0171517826413645, Val Loss: 260281940.7324996\n",
      "Epoch 44, Training Loss: 0.016952203457047104, Val Loss: 298984720.5885628\n",
      "Epoch 45, Training Loss: 0.016766802852934446, Val Loss: 304703060.73239475\n",
      "Epoch 46, Training Loss: 0.01658594924437958, Val Loss: 413121440.24312913\n",
      "Epoch 47, Training Loss: 0.016406018040607533, Val Loss: 453672105.4517059\n",
      "Epoch 48, Training Loss: 0.01622834550800221, Val Loss: 604717350.6890622\n",
      "Epoch 49, Training Loss: 0.01605150935276824, Val Loss: 572625102.2861363\n",
      "Epoch 50, Training Loss: 0.015883685504529288, Val Loss: 676416799.3220702\n",
      "Epoch 51, Training Loss: 0.01572210543946711, Val Loss: 400536377.10621154\n",
      "Epoch 52, Training Loss: 0.015557500747682878, Val Loss: 414752384.9335185\n",
      "Epoch 53, Training Loss: 0.01539865027240147, Val Loss: 378159428.1565122\n",
      "Epoch 54, Training Loss: 0.015247641094547551, Val Loss: 407937937.509005\n",
      "Epoch 55, Training Loss: 0.015095870887856334, Val Loss: 719207387.1780403\n",
      "Epoch 56, Training Loss: 0.014946533103415142, Val Loss: 746334104.8758628\n",
      "Epoch 57, Training Loss: 0.014792299570122479, Val Loss: 779737250.0844679\n",
      "Epoch 58, Training Loss: 0.014645600388919948, Val Loss: 763554101.4225612\n",
      "Epoch 59, Training Loss: 0.014499257573654785, Val Loss: 859174543.6671301\n",
      "Epoch 60, Training Loss: 0.014352428389760707, Val Loss: 785994877.2498262\n",
      "Epoch 61, Training Loss: 0.014209126835373466, Val Loss: 826531368.530358\n",
      "Epoch 62, Training Loss: 0.014062215303980557, Val Loss: 654398530.3144931\n",
      "Epoch 63, Training Loss: 0.013912534215887295, Val Loss: 828464150.1130116\n",
      "Epoch 64, Training Loss: 0.01376823967067728, Val Loss: 823474868.501454\n",
      "Epoch 65, Training Loss: 0.013626287699938512, Val Loss: 784162816.0122086\n",
      "Epoch 66, Training Loss: 0.013485909145748947, Val Loss: 1044424247.2639676\n",
      "Epoch 67, Training Loss: 0.013345937808573662, Val Loss: 959025770.832287\n",
      "Epoch 68, Training Loss: 0.013205460877764945, Val Loss: 1107369689.3358555\n",
      "Epoch 69, Training Loss: 0.013067783999609006, Val Loss: 1096618838.5732424\n",
      "Epoch 70, Training Loss: 0.012931076779512132, Val Loss: 1184296694.8034341\n",
      "Epoch 71, Training Loss: 0.012798939453407673, Val Loss: 1170980746.141558\n",
      "Epoch 72, Training Loss: 0.01266842009175543, Val Loss: 1237431892.7314763\n",
      "Epoch 73, Training Loss: 0.012539130259573183, Val Loss: 1262585929.6811023\n",
      "Epoch 74, Training Loss: 0.012413898720611275, Val Loss: 1275583274.371735\n",
      "Epoch 75, Training Loss: 0.012287226209542314, Val Loss: 1396853634.774609\n",
      "Epoch 76, Training Loss: 0.0121610339908167, Val Loss: 1402023317.191875\n",
      "Epoch 77, Training Loss: 0.012035811823423252, Val Loss: 1519205692.7889807\n",
      "Epoch 78, Training Loss: 0.011911069220169653, Val Loss: 1423748972.6738615\n",
      "Epoch 79, Training Loss: 0.011782587756534601, Val Loss: 1432683203.2350302\n",
      "Epoch 80, Training Loss: 0.011652996733335221, Val Loss: 1487488272.587582\n",
      "Epoch 81, Training Loss: 0.011526772812907768, Val Loss: 1634972561.508451\n",
      "Epoch 82, Training Loss: 0.011410823288501138, Val Loss: 1642960291.9256895\n",
      "Epoch 83, Training Loss: 0.011278062585628917, Val Loss: 1768383112.299821\n",
      "Epoch 84, Training Loss: 0.011144895422036852, Val Loss: 1824006556.5588813\n",
      "Epoch 85, Training Loss: 0.011016659120966414, Val Loss: 1899380736.0121174\n",
      "Epoch 86, Training Loss: 0.010933758312806038, Val Loss: 1763632459.5228279\n",
      "Epoch 87, Training Loss: 0.010792143473276337, Val Loss: 2230576695.2638493\n",
      "Epoch 88, Training Loss: 0.010721969592175392, Val Loss: 2299964231.8395185\n",
      "Epoch 89, Training Loss: 0.010608329460361925, Val Loss: 2284296177.27858\n",
      "Epoch 90, Training Loss: 0.010807660344573226, Val Loss: 2241106067.3504987\n",
      "Epoch 91, Training Loss: 0.011506819053879331, Val Loss: 2451490300.329072\n",
      "Epoch 92, Training Loss: 0.011665415701622753, Val Loss: 2269487162.9474134\n",
      "Epoch 93, Training Loss: 0.011307638456176302, Val Loss: 2004297860.6171682\n",
      "Epoch 94, Training Loss: 0.011131611036832537, Val Loss: 2716848628.961918\n",
      "Epoch 95, Training Loss: 0.010249744137001424, Val Loss: 2578909021.9401994\n",
      "Epoch 96, Training Loss: 0.010243729995066633, Val Loss: 2866483347.350245\n",
      "Epoch 97, Training Loss: 0.010036817764789903, Val Loss: 2775724474.0265136\n",
      "Epoch 98, Training Loss: 0.009848823168005992, Val Loss: 2847720956.328819\n",
      "Epoch 99, Training Loss: 0.009731409147494147, Val Loss: 2998395056.8180437\n",
      "Epoch 100, Training Loss: 0.009623589799058755, Val Loss: 3173878305.163372\n"
     ]
    }
   ],
   "source": [
    "epoch=100\n",
    "run(model, train_dataloader,val_dataloader, test_dataloader, device, epoch,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Luzon GWAP: Training, Validation, and Test Losses Over Epochs')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
