{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r'/Users/jojielyn/Desktop/School/04 Senior/Thesis/SARIMAX/Mindanao/MIN_Daily_Complete.csv'\n",
    "data = pd.read_csv(input_file)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_columns(df, value, substrings_ffill, substrings_interpolate):\n",
    "    # Replace -999 with NaN\n",
    "    df = df.replace(value, np.nan)\n",
    "    \n",
    "    # Forward fill for specified substrings\n",
    "    ffill_cols = df.loc[:, df.columns.str.contains('|'.join(substrings_ffill), case=False)]\n",
    "    ffill_cols = ffill_cols.ffill()\n",
    "    \n",
    "    # Interpolate for specified substrings\n",
    "    interpolate_cols = df.loc[:, df.columns.str.contains('|'.join(substrings_interpolate), case=False)]\n",
    "    interpolate_cols = interpolate_cols.interpolate(method='linear')\n",
    "    \n",
    "    return ffill_cols, interpolate_cols\n",
    "\n",
    "columns_with_minus_999 = data.loc[:, (data == -999).any(axis=0)]\n",
    "\n",
    "# Process columns\n",
    "rainfall_cols, temp_cols_interpolated = process_columns(\n",
    "    columns_with_minus_999, \n",
    "    -999, \n",
    "    substrings_ffill=['rainfall'], \n",
    "    substrings_interpolate=['tmax', 'tmin']\n",
    ")\n",
    "X = data.copy()\n",
    "X[rainfall_cols.columns] = rainfall_cols\n",
    "X[temp_cols_interpolated.columns] = temp_cols_interpolated\n",
    "y = data[['GWAP','LWAP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(X))  # 80% for training\n",
    "test_size = len(X) - train_size  # Remaining 20% for testing\n",
    "\n",
    "train_data = X[:train_size]\n",
    "train_labels = y[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FLOW_MIN', 'Hourly Demand', 'TMIN_Davao City', 'TMAX_Surigao', 'TMIN_Surigao', 'TMIN_Zamboanga', 'TMIN_Butuan', 'TMAX_Malaybalay', 'TMAX_General Santos']\n",
      "['GWAP', 'LWAP', 'TMAX_Davao City', 'TMAX_Zamboanga', 'TMAX_Dipolog', 'TMIN_Dipolog', 'TMAX_Butuan', 'TMIN_Malaybalay', 'TMAX_Cotabato', 'TMIN_Cotabato']\n",
      "['RESERVE_GWAP_Fr', 'RESERVE_GWAP_Ru', 'RESERVE_GWAP_Rd', 'RESERVE_GWAP_Dr', 'RAINFALL_Davao City', 'RAINFALL_Surigao', 'RAINFALL_Zamboanga', 'RAINFALL_Dipolog', 'RAINFALL_Butuan', 'RAINFALL_Malaybalay', 'RAINFALL_General Santos', 'TMIN_General Santos', 'RAINFALL_Cotabato']\n"
     ]
    }
   ],
   "source": [
    "print(minmax_cols)\n",
    "print(boxcox_cols)\n",
    "print(yeojohnson_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_cols = []\n",
    "boxcox_cols = []\n",
    "yeojohnson_cols = []\n",
    "\n",
    "# Classify columns into MinMax, BoxCox, or YeoJohnson families\n",
    "def classify_features(data):\n",
    "    for column in data.columns:\n",
    "        col_data = data[column]\n",
    "        skewness = col_data.skew()\n",
    "        kurt = col_data.kurtosis()\n",
    "        is_positive = np.all(col_data > 0)\n",
    "\n",
    "        if -1 <= skewness <= 1 and -1 <= kurt <= 1:\n",
    "            minmax_cols.append(column)  # MinMax family\n",
    "        elif is_positive:\n",
    "            boxcox_cols.append(column)  # BoxCox family\n",
    "        else:\n",
    "            yeojohnson_cols.append(column)  # YeoJohnson family\n",
    "\n",
    "classify_features(data)\n",
    "\n",
    "minmax_colsy = []\n",
    "boxcox_colsy = []\n",
    "yeojohnson_colsy = []\n",
    "\n",
    "def classify_features(data):\n",
    "    for column in data.columns:\n",
    "        col_data = data[column]\n",
    "        skewness = col_data.skew()\n",
    "        kurt = col_data.kurtosis()\n",
    "        is_positive = np.all(col_data > 0)\n",
    "\n",
    "        if -1 <= skewness <= 1 and -1 <= kurt <= 1:\n",
    "            minmax_colsy.append(column)  # MinMax family\n",
    "        elif is_positive:\n",
    "            boxcox_colsy.append(column)  # BoxCox family\n",
    "        else:\n",
    "            yeojohnson_colsy.append(column)  # YeoJohnson family\n",
    "\n",
    "classify_features(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.DataFrame(train_data)\n",
    "minmax_test = MinMaxScaler(feature_range=(0, 1))\n",
    "minmaxfit = minmax_test.fit(train_data_df[minmax_cols])\n",
    "train_data_minmax = minmaxfit.transform(train_data_df[minmax_cols])\n",
    "joblib.dump(minmaxfit, 'minmax_scaler.pkl')\n",
    "boxcox_pipeline = Pipeline([\n",
    "    ('boxcox', PowerTransformer(method='box-cox', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "bc = boxcox_pipeline.fit(train_data_df[boxcox_cols])\n",
    "train_data_bc = bc.transform(train_data_df[boxcox_cols])\n",
    "joblib.dump(bc, 'boxcox_pipeline.pkl')\n",
    "yeojohnson_pipeline = Pipeline([\n",
    "    ('yeojohnson', PowerTransformer(method='yeo-johnson', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "yj = yeojohnson_pipeline.fit(train_data_df[yeojohnson_cols])\n",
    "train_data_yj = yj.transform(train_data_df[yeojohnson_cols])\n",
    "joblib.dump(yj, 'yeojohnson_pipeline.pkl')\n",
    "train_data_transformed = np.hstack([train_data_minmax, train_data_bc, train_data_yj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boxcox_pipeliney.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = pd.DataFrame(train_labels)\n",
    "\n",
    "boxcox_pipeline = Pipeline([\n",
    "    ('boxcox', PowerTransformer(method='box-cox', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "bcy = boxcox_pipeline.fit(train_data_df[boxcox_colsy])\n",
    "joblib.dump(bcy, 'boxcox_pipeliney.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_transformed = bcy.transform(train_labels_df[boxcox_colsy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_transformed = pd.DataFrame(train_labels_transformed)\n",
    "train_data_transformed = pd.DataFrame(train_data_transformed)\n",
    "train_labels_transformed.to_csv('train_labels_transformed.csv', index=False)\n",
    "train_data_transformed.to_csv('train_data_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X[train_size:]\n",
    "test_labels = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_labels.to_csv('test_labels.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X[train_size:]\n",
    "\n",
    "test_data_df = pd.DataFrame(test_data)\n",
    "minmax_test = MinMaxScaler(feature_range=(0, 1))\n",
    "minmaxfit = minmax_test.fit(test_data_df[minmax_cols])\n",
    "test_data_minmax = minmaxfit.transform(test_data_df[minmax_cols])\n",
    "joblib.dump(minmaxfit, 'minmax_scaler.pkl')\n",
    "boxcox_pipeline = Pipeline([\n",
    "    ('boxcox', PowerTransformer(method='box-cox', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "bc = boxcox_pipeline.fit(test_data_df[boxcox_cols])\n",
    "test_data_bc = bc.transform(test_data_df[boxcox_cols])\n",
    "joblib.dump(bc, 'boxcox_pipeline.pkl')\n",
    "yeojohnson_pipeline = Pipeline([\n",
    "    ('yeojohnson', PowerTransformer(method='yeo-johnson', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "yj = yeojohnson_pipeline.fit(test_data_df[yeojohnson_cols])\n",
    "test_data_yj = yj.transform(test_data_df[yeojohnson_cols])\n",
    "joblib.dump(yj, 'yeojohnson_pipeline.pkl')\n",
    "test_data_transformed = np.hstack([test_data_minmax, test_data_bc, test_data_yj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_transformed = pd.DataFrame(test_data_transformed)\n",
    "test_data_transformed.to_csv('test_data_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "minmax_test = MinMaxScaler(feature_range=(0, 1))\n",
    "minmaxfit = minmax_test.fit(data_df[minmax_cols])\n",
    "data_minmax = minmaxfit.transform(data_df[minmax_cols])\n",
    "joblib.dump(minmaxfit, 'minmax_scaler.pkl')\n",
    "boxcox_pipeline = Pipeline([\n",
    "    ('boxcox', PowerTransformer(method='box-cox', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "bc = boxcox_pipeline.fit(data_df[boxcox_cols])\n",
    "data_bc = bc.transform(data_df[boxcox_cols])\n",
    "joblib.dump(bc, 'boxcox_pipeline.pkl')\n",
    "yeojohnson_pipeline = Pipeline([\n",
    "    ('yeojohnson', PowerTransformer(method='yeo-johnson', standardize=False)),\n",
    "    ('minmax', MinMaxScaler(feature_range=(0, 1)))\n",
    "])\n",
    "yj = yeojohnson_pipeline.fit(data_df[yeojohnson_cols])\n",
    "data_yj = yj.transform(data_df[yeojohnson_cols])\n",
    "joblib.dump(yj, 'yeojohnson_pipeline.pkl')\n",
    "data_transformed = np.hstack([data_minmax, data_bc, data_yj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = pd.DataFrame(data_transformed)\n",
    "data_transformed.to_csv('data_transformed.csv', index=False)\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
